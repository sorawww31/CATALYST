# Gradient Descent with Line-search Step-size to Minimize Both Training Loss and Adversarial Loss in Data Poisoning Attacks
## Abstract:
Data poisoning attacks alter the training data with the intent of maliciously influencing the behavior of a model trained on that data. In this paper, we focus on the relationship between step-sizes and targeted data poisoning attacks that cause the misclassification of unmodified data. We aim to solve the bilevel optimization problem to minimize both training loss and adversarial loss in data poisoning attacks. We specifically leverage the Wolfe line-search step-sizes that play a crucial role in solving the bilevel optimization problem in data poisoning attacks or enhancing the effectiveness of a poison of these attacks. The main mechanism of our method, presented in this paper, involves matching the gradient direction of malicious examples trained by gradient descent with the gradient of the training loss and incorporating the Wolfe line-search step-sizes based on adversarial loss during poisoned training. We validate effectiveness of our method through experiments on benchmark datasets, demonstrating that it surpasses the existing methods, GM and SAPA, in attack success, achieving an improvement of 3\% to 10\% compared to recent works. Additionally, we highlight the limitations of current defense mechanisms, emphasizing the urgent need for more robust strategies to counteract advanced data poisoning attacks.